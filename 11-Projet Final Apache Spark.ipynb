{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Final Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nom Etudiant :**  Serigne  Saliou\n",
    "\n",
    "**Prenom Etudiant:**  Gueye\n",
    "\n",
    "**Classe :**  Master Intelligence Artificielle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Ce projet consiste à utiliser Apache Spark pour faire l'analyse et le traitement des données de **[San Francisco Fire Department Calls ](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)** afin de fournir quelques KPI (*Key Performance Indicator*). Le **SF Fire Dataset** comprend les réponses aux appels de toutes les unités d'incendie. Chaque enregistrement comprend le numéro d'appel, le numéro d'incident, l'adresse, l'identifiant de l'unité, le type d'appel et la disposition. Tous les intervalles de temps pertinents sont également inclus. Étant donné que ce Dataset est basé sur les réponses et que la plupart des appels impliquent plusieurs unités, ainsi il existe plusieurs enregistrements pour chaque numéro d'appel. Les adresses sont associées à un numéro de bloc, à une intersection ou à une boîte d'appel, et non à une adresse spécifique.\n",
    "\n",
    "**Plus de details sur la description des données cliquer sur ce [lien](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail à faire.\n",
    "L'objectif de ce projet est de comprendre le **SF Fire Dataset** afin de bien répondre aux questions en utilisant les codes Spark/Scala adéquates.\n",
    "\n",
    "- Créer un repos git (public ou privé) et partager le repos avec mon mail (limahin10@gmail.com)\n",
    "- Ecrire un code lisible et bien indenté \n",
    "- N'oublier pas de mettre en commentaire la justification de vos réponses sur les cellules Markdown. \n",
    "\n",
    "\n",
    "## Note:\n",
    "- Le projet est personnel, c'est-à-dire chaque notebook ne concerne qu'un seul étudiant. \n",
    "- Deadline : **Jeudi 10 janvier 2021** (Aucune de dérogation ne sera acceptée)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des packages Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "import spark.implicits._\r\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._ \n",
    "import org.apache.spark.sql.functions._ \n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons jeter un coup d'oeil sur la structure des données avant de définir un schéma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallNumber,UnitID,IncidentNumber,CallType,CallDate,WatchDate,CallFinalDisposition,AvailableDtTm,Address,City,Zipcode,Battalion,StationArea,Box,OriginalPriority,Priority,FinalPriority,ALSUnit,CallTypeGroup,NumAlarms,UnitType,UnitSequenceInCallDispatch,FirePreventionDistrict,SupervisorDistrict,Neighborhood,Location,RowID,Delay\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!head -1 \"datasets/sf-fire/sf-fire-calls.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu que la taille de ces données est énormes, inferer le schema pour un très grande volumes de données s'avère un peu couteux. Nous allons ainsi définir un schema pour le Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fireSchema: org.apache.spark.sql.types.StructType = StructType(StructField(CallNumber,IntegerType,true), StructField(UnitID,StringType,true), StructField(IncidentNumber,IntegerType,true), StructField(CallType,StringType,true), StructField(CallDate,StringType,true), StructField(WatchDate,StringType,true), StructField(CallFinalDisposition,StringType,true), StructField(AvailableDtTm,StringType,true), StructField(Address,StringType,true), StructField(City,StringType,true), StructField(Zipcode,IntegerType,true), StructField(Battalion,StringType,true), StructField(StationArea,StringType,true), StructField(Box,StringType,true), StructField(OriginalPriority,StringType,true), StructField(Priority,StringType,true), StructField(FinalPriority,IntegerType,true), StructField(ALSUnit,BooleanType,true)...\r\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fireSchema = StructType(Array(StructField(\"CallNumber\", IntegerType, true),\n",
    "  StructField(\"UnitID\", StringType, true),\n",
    "  StructField(\"IncidentNumber\", IntegerType, true),\n",
    "  StructField(\"CallType\", StringType, true),                  \n",
    "  StructField(\"CallDate\", StringType, true),      \n",
    "  StructField(\"WatchDate\", StringType, true),\n",
    "  StructField(\"CallFinalDisposition\", StringType, true),\n",
    "  StructField(\"AvailableDtTm\", StringType, true),\n",
    "  StructField(\"Address\", StringType, true),       \n",
    "  StructField(\"City\", StringType, true),       \n",
    "  StructField(\"Zipcode\", IntegerType, true),       \n",
    "  StructField(\"Battalion\", StringType, true),                 \n",
    "  StructField(\"StationArea\", StringType, true),       \n",
    "  StructField(\"Box\", StringType, true),       \n",
    "  StructField(\"OriginalPriority\", StringType, true),       \n",
    "  StructField(\"Priority\", StringType, true),       \n",
    "  StructField(\"FinalPriority\", IntegerType, true),       \n",
    "  StructField(\"ALSUnit\", BooleanType, true),       \n",
    "  StructField(\"CallTypeGroup\", StringType, true),\n",
    "  StructField(\"NumAlarms\", IntegerType, true),\n",
    "  StructField(\"UnitType\", StringType, true),\n",
    "  StructField(\"UnitSequenceInCallDispatch\", IntegerType, true),\n",
    "  StructField(\"FirePreventionDistrict\", StringType, true),\n",
    "  StructField(\"SupervisorDistrict\", StringType, true),\n",
    "  StructField(\"Neighborhood\", StringType, true),\n",
    "  StructField(\"Location\", StringType, true),\n",
    "  StructField(\"RowID\", StringType, true),\n",
    "  StructField(\"Delay\", FloatType, true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sfFireFile: String = datasets/sf-fire/sf-fire-calls.csv\r\n",
       "fireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\r\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sfFireFile = \"datasets/sf-fire/sf-fire-calls.csv\"\n",
    "val fireDF = spark\n",
    "  .read\n",
    "  .schema(fireSchema)\n",
    "  .option(\"header\", \"true\")\n",
    "  .csv(sfFireFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons mettre en cache le Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: fireDF.type = [CallNumber: int, UnitID: string ... 26 more fields]\r\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res38: Long = 175296\r\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         null|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         null|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         null|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrage des d'appels de type \"Medical Incident\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+-----------------------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType                     |\n",
      "+--------------+----------------------+-----------------------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire               |\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire                 |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms                       |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire               |\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms                       |\n",
      "|2003304       |01/11/2002 09:58:53 AM|Alarms                       |\n",
      "|2003382       |01/11/2002 02:59:04 PM|Structure Fire               |\n",
      "|2003408       |01/11/2002 04:09:08 PM|Structure Fire               |\n",
      "|2003408       |01/11/2002 04:09:08 PM|Structure Fire               |\n",
      "|2003408       |01/11/2002 04:09:08 PM|Structure Fire               |\n",
      "|2003429       |01/11/2002 05:17:15 PM|Odor (Strange / Unknown)     |\n",
      "|2003453       |01/11/2002 06:48:01 PM|Alarms                       |\n",
      "|2003497       |01/11/2002 09:03:17 PM|Structure Fire               |\n",
      "|2003554       |01/12/2002 01:56:32 AM|Structure Fire               |\n",
      "|2003618       |01/12/2002 11:07:36 AM|Odor (Strange / Unknown)     |\n",
      "|2003649       |01/12/2002 01:03:10 PM|Odor (Strange / Unknown)     |\n",
      "|2003695       |01/12/2002 04:46:59 PM|Structure Fire               |\n",
      "|2003756       |01/12/2002 07:54:42 PM|Alarms                       |\n",
      "|2003770       |01/12/2002 08:44:01 PM|Smoke Investigation (Outside)|\n",
      "|2003777       |01/12/2002 09:14:13 PM|Structure Fire               |\n",
      "+--------------+----------------------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fewFireDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, AvailableDtTm: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fewFireDF = fireDF\n",
    "  .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\") \n",
    "  .where($\"CallType\" =!= \"Medical Incident\")\n",
    "\n",
    "fewFireDF.show(20, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "**Combien de types d'appels distincts ont été passés ?**  \n",
    "Pour être sûr, il ne faut pas compter les valeurs «nulles» dans la colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de type d'appel distincte : 29\n",
      "+--------------+----------------------+--------------------------------------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType                                    |\n",
      "+--------------+----------------------+--------------------------------------------+\n",
      "|2008447       |01/29/2002 04:58:55 AM|Elevator / Escalator Rescue                 |\n",
      "|5092002       |12/06/2005 04:41:49 PM|Marine Fire                                 |\n",
      "|2013793       |02/15/2002 07:19:48 PM|Aircraft Emergency                          |\n",
      "|11112063      |12/04/2011 04:16:46 PM|Confined Space / Structure Collapse         |\n",
      "|6007230       |01/26/2006 02:37:40 PM|Administrative                              |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms                                      |\n",
      "|2003429       |01/11/2002 05:17:15 PM|Odor (Strange / Unknown)                    |\n",
      "|2004152       |01/14/2002 08:16:54 AM|Citizen Assist / Service Call               |\n",
      "|2057385       |07/11/2002 09:43:51 PM|HazMat                                      |\n",
      "|6036736       |05/13/2006 01:36:22 AM|Watercraft in Distress                      |\n",
      "|3006451       |01/23/2003 04:23:41 AM|Explosion                                   |\n",
      "|2056044       |07/07/2002 03:56:42 PM|Oil Spill                                   |\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire                                |\n",
      "|2032165       |04/18/2002 06:43:49 PM|Suspicious Package                          |\n",
      "|3027074       |04/03/2003 11:07:15 PM|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|2003916       |01/13/2002 12:34:42 PM|Other                                       |\n",
      "|2004091       |01/13/2002 11:16:07 PM|Outside Fire                                |\n",
      "|2095239       |11/17/2002 11:21:27 AM|Traffic Collision                           |\n",
      "|3023190       |03/21/2003 08:24:00 PM|Assist Police                               |\n",
      "|2012597       |02/11/2002 07:00:20 PM|Gas Leak (Natural and LP Gases)             |\n",
      "+--------------+----------------------+--------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "noNullFewFireDFCallType: org.apache.spark.sql.DataFrame = [IncidentNumber: int, AvailableDtTm: string ... 1 more field]\r\n",
       "dropDisCallType: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, AvailableDtTm: string ... 1 more field]\r\n",
       "res42: org.apache.spark.sql.DataFrame = [count(DISTINCT CallType): bigint]\r\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Reponse 1\n",
    "/*\n",
    "\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "//suppresion des valeurs nulles de la colonne CallType\n",
    "val noNullFewFireDFCallType=  fewFireDF.na.drop(cols=Seq(\"CallType\"))\n",
    "//on utilise dropDuplicates pour supprimer les dupplicata\n",
    "val dropDisCallType = noNullFewFireDFCallType.dropDuplicates(\"CallType\")\n",
    "//on affiche le nombre de valeur distinc en utilisant la fonction count()\n",
    "  println(\"Le nombre de type d'appel distincte : \"+dropDisCallType.count())\n",
    "  dropDisCallType.show(false)\n",
    "noNullFewFireDFCallType.select(countDistinct(\"CallType\"))\n",
    "\n",
    "//noNullFewFireDFCallType.groupBy(\"CallType\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT CallType)|\n",
      "+------------------------+\n",
      "|                      29|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "//on peut aussi utiliser la fonction countdistinct\n",
    "noNullFewFireDFCallType.select(countDistinct(\"CallType\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quels types d'appels différents ont été passés au service d'incendie?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            CallType|\n",
      "+--------------------+\n",
      "|Elevator / Escala...|\n",
      "|         Marine Fire|\n",
      "|  Aircraft Emergency|\n",
      "|Confined Space / ...|\n",
      "|      Administrative|\n",
      "|              Alarms|\n",
      "|Odor (Strange / U...|\n",
      "|Citizen Assist / ...|\n",
      "|              HazMat|\n",
      "|Watercraft in Dis...|\n",
      "|           Explosion|\n",
      "|           Oil Spill|\n",
      "|        Vehicle Fire|\n",
      "|  Suspicious Package|\n",
      "|Extrication / Ent...|\n",
      "|               Other|\n",
      "|        Outside Fire|\n",
      "|   Traffic Collision|\n",
      "|       Assist Police|\n",
      "|Gas Leak (Natural...|\n",
      "|        Water Rescue|\n",
      "|   Electrical Hazard|\n",
      "|   High Angle Rescue|\n",
      "|      Structure Fire|\n",
      "|Industrial Accidents|\n",
      "|Mutual Aid / Assi...|\n",
      "|          Fuel Spill|\n",
      "|Smoke Investigati...|\n",
      "|Train / Rail Inci...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Reponse 2\n",
    "/*\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "//types d'appels différents ont été passés au service d'incendie\n",
    "  dropDisCallType.select(\"CallType\").show(29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "**Trouver toutes les réponses ou les délais sont supérieurs à 5 minutes?**\n",
    "\n",
    "*Indication\n",
    "1. Renommer la colonne Delay -> ReponseDelayedinMins\n",
    "2. Retourner un nouveau DataFrame\n",
    "3. Afficher tous les appels où le temps de réponse à un site d'incendie a eu lieu après un retard de plus de 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+\n",
      "|CallNumber|ResponseDelayedinMins|\n",
      "+----------+---------------------+\n",
      "|  20110315|                 5.35|\n",
      "|  20120147|                 6.25|\n",
      "|  20130013|                  5.2|\n",
      "|  20140067|                  5.6|\n",
      "|  20140177|                 7.25|\n",
      "|  20150056|            11.916667|\n",
      "|  20150254|             5.116667|\n",
      "|  20150265|             8.633333|\n",
      "|  20150265|             95.28333|\n",
      "|  20150380|                 5.45|\n",
      "|  20150414|                  7.6|\n",
      "|  20160059|             6.133333|\n",
      "|  20160064|            5.1833334|\n",
      "|  20170118|            6.9166665|\n",
      "|  20170342|                  5.2|\n",
      "|  20180129|                 6.35|\n",
      "|  20180191|             7.983333|\n",
      "|  20180382|                13.55|\n",
      "|  20190062|                 5.15|\n",
      "|  20190097|            13.583333|\n",
      "+----------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newFireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\r\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Reponse 3\n",
    "\n",
    "val newFireDF = fireDF.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "//on chosit le numero d\"ppel et le temps de reponse et on filtre ce qui sont plus grand que 5\n",
    "newFireDF.select(\"CallNumber\",\"ResponseDelayedinMins\").filter(\"ResponseDelayedinMins>5\").show()\n",
    "\n",
    "/*\n",
    "Completer le code\n",
    "*/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations des dates\n",
    "Maintenant nous allons d'abord:\n",
    "1. Transformer les dates de type String en Spark Timestamp afin que nous puissions effectuer des requêtes basées sur la date plus tard\n",
    "2. Retourner le Dataframe transformée\n",
    "3. Mettre en cache le nouveau DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fireTSDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\r\n",
       "res46: fireTSDF.type = [CallNumber: int, UnitID: string ... 26 more fields]\r\n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fireTSDF = newFireDF\n",
    "  .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\")).drop(\"CallDate\") \n",
    "  .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\")).drop(\"WatchDate\") \n",
    "  .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), \"MM/dd/yyyy hh:mm:ss a\")).drop(\"AvailableDtTm\")\n",
    "\n",
    "fireTSDF.cache()\n",
    "//fireTSDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "**Quels sont les types d'appels les plus courants?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            CallType| count|\n",
      "+--------------------+------+\n",
      "|    Medical Incident|113794|\n",
      "|      Structure Fire| 23319|\n",
      "|              Alarms| 19406|\n",
      "|   Traffic Collision|  7013|\n",
      "|Citizen Assist / ...|  2524|\n",
      "|               Other|  2166|\n",
      "|        Outside Fire|  2094|\n",
      "|        Vehicle Fire|   854|\n",
      "|Gas Leak (Natural...|   764|\n",
      "|        Water Rescue|   755|\n",
      "|Odor (Strange / U...|   490|\n",
      "|   Electrical Hazard|   482|\n",
      "|Elevator / Escala...|   453|\n",
      "|Smoke Investigati...|   391|\n",
      "|          Fuel Spill|   193|\n",
      "|              HazMat|   124|\n",
      "|Industrial Accidents|    94|\n",
      "|           Explosion|    89|\n",
      "|Train / Rail Inci...|    57|\n",
      "|  Aircraft Emergency|    36|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fireTSDF2: Unit = ()\r\n"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse4\n",
    "\n",
    "\n",
    "/*\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "//pour cette question on regroupe les type d'appel et on compte leur nombre et onsuite on les range par ordre decroissant\n",
    "val fireTSDF2= fireTSDF.groupBy(\"CallType\").count().sort(desc(\"count\")).show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5-a\n",
    "**Quels sont boites postaux rencontrés dans les appels les plus courants?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+-----+\n",
      "|        CallType|Zipcode|count|\n",
      "+----------------+-------+-----+\n",
      "|Medical Incident|  94102|16130|\n",
      "|Medical Incident|  94103|14775|\n",
      "|Medical Incident|  94110| 9995|\n",
      "|Medical Incident|  94109| 9479|\n",
      "|Medical Incident|  94124| 5885|\n",
      "|Medical Incident|  94112| 5630|\n",
      "|Medical Incident|  94115| 4785|\n",
      "|Medical Incident|  94122| 4323|\n",
      "|Medical Incident|  94107| 4284|\n",
      "|Medical Incident|  94133| 3977|\n",
      "|Medical Incident|  94117| 3522|\n",
      "|Medical Incident|  94134| 3437|\n",
      "|Medical Incident|  94114| 3225|\n",
      "|Medical Incident|  94118| 3104|\n",
      "|Medical Incident|  94121| 2953|\n",
      "|Medical Incident|  94116| 2738|\n",
      "|Medical Incident|  94132| 2594|\n",
      "|  Structure Fire|  94110| 2267|\n",
      "|Medical Incident|  94105| 2258|\n",
      "|  Structure Fire|  94102| 2229|\n",
      "+----------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fireTSDF2: Unit = ()\r\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 5-a\n",
    "/*\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "val fireTSDF2= fireTSDF.groupBy(\"CallType\",\"Zipcode\").count().sort(desc(\"count\")).show()\n",
    "\n",
    "//fireTSDF2=fireTSDF.withColumn(\"TypeAppePlusfrequent\",fireTSDF.groupBy(\"CallType\").count().sort(desc(\"count\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5-a\n",
    "**Quels sont les quartiers de San Francisco dont les codes postaux sont 94102 et 94103?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----+\n",
      "|Zipcode|             Address|city|\n",
      "+-------+--------------------+----+\n",
      "|  94102|MARKET ST/MCALLIS...|  SF|\n",
      "|  94102|600 Block of POLK ST|  SF|\n",
      "|  94103|    9TH ST/HOWARD ST|  SF|\n",
      "|  94103|400 Block of VALE...|  SF|\n",
      "|  94103|  16TH ST/MISSION ST|  SF|\n",
      "|  94103|   4TH ST/MISSION ST|  SF|\n",
      "|  94102|400 Block of TURK ST|  SF|\n",
      "|  94102|   OAK ST/WEBSTER ST|  SF|\n",
      "|  94102| 0 Block of JONES ST|  SF|\n",
      "|  94102|400 Block of EDDY ST|  SF|\n",
      "|  94103|300 Block of CLEM...|  SF|\n",
      "|  94102| 500 Block of OAK ST|  SF|\n",
      "|  94103|700 Block of MARK...|  SF|\n",
      "|  94102|HAIGHT ST/OCTAVIA ST|  SF|\n",
      "|  94103|100 Block of JULI...|  SF|\n",
      "|  94102|0 Block of LARKIN ST|  SF|\n",
      "|  94102|100 Block of TURK ST|  SF|\n",
      "|  94102|CALL BOX: BUCHANA...|  SF|\n",
      "|  94103|    5TH ST/MARKET ST|  SF|\n",
      "|  94103| 100 Block of 7TH ST|  SF|\n",
      "+-------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "street_zipcode: Unit = ()\r\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 5-b\n",
    "/*\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "val street_zipcode=fireTSDF.select(\"Zipcode\",\"Address\",\"city\").filter($\"Zipcode\" === 94102 || $\"Zipcode\"=== 94103).show()\n",
    "\n",
    "//fireTSDF.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "**Determiner le nombre total d'appels, ainsi que la moyenne, le minimum et le maximum du temps de réponse des appels?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|    175296|\n",
      "+----------+\n",
      "\n",
      "+--------------------------+\n",
      "|avg(ResponseDelayedinMins)|\n",
      "+--------------------------+\n",
      "|         3.892364154521585|\n",
      "+--------------------------+\n",
      "\n",
      "+--------------------------+\n",
      "|min(ResponseDelayedinMins)|\n",
      "+--------------------------+\n",
      "|               0.016666668|\n",
      "+--------------------------+\n",
      "\n",
      "+--------------------------+\n",
      "|max(ResponseDelayedinMins)|\n",
      "+--------------------------+\n",
      "|                   1844.55|\n",
      "+--------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fireTSDF2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [CallType: string, count: bigint]\r\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 6\n",
    "/*\n",
    "Pour chaque type d'appels on compte son nombre,ensuite on fait la somme\n",
    "*/\n",
    "//fireTSDF.printSchema()\n",
    "//Pour chaque type d'appels on compte son nombre\n",
    "val fireTSDF2= fireTSDF.groupBy(\"CallType\").count().sort(desc(\"count\"))\n",
    "//on fait le somme du colonne pour avoir le nombre total d'appel\n",
    "fireTSDF2.select(sum(\"count\")).show()\n",
    "//moyenne,maximum,minumum\n",
    "fireTSDF.select(mean(\"ResponseDelayedinMins\")).show()\n",
    "//minimum\n",
    "fireTSDF.select(min(\"ResponseDelayedinMins\")).show()\n",
    "//maximum\n",
    "fireTSDF.select(max(\"ResponseDelayedinMins\")).show()\n",
    "// heure\n",
    "//reTSDF.select(hour(max(\"ResponseDelayedinMins\"))).show()\n",
    "\n",
    "//reTSDF.groupBy(\"ResponseDelayedinMins\").mean().select(\"ResponseDelayedinMins\",\"avg(ResponseDelayedinMins)\").show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7-a\n",
    "**Combien d'années distinctes trouve t-on dans ce Dataset?**  \n",
    "Dans ce dataset nous avons des données comprises entre 2000-2018. Vous pouvez utilisez la fonction Spark `year()` pour les dates en Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|count(DISTINCT year(CAST(AvailableDtTS AS DATE)))|\n",
      "+-------------------------------------------------+\n",
      "|                                               19|\n",
      "+-------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Reponse 7-a\n",
    "/*\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "fireTSDF.select(countDistinct(year(fireTSDF(\"AvailableDtTS\")))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7-b\n",
    "**Quelle semaine de l'année 2018 a eu le plus d'appels d'incendie?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|semaine|count|\n",
      "+-------+-----+\n",
      "|      1|   37|\n",
      "|     43|   35|\n",
      "|     25|   33|\n",
      "|      8|   32|\n",
      "|     27|   31|\n",
      "|     44|   31|\n",
      "|     38|   30|\n",
      "|     26|   30|\n",
      "|     11|   29|\n",
      "|     40|   29|\n",
      "|     15|   28|\n",
      "|     28|   28|\n",
      "|      7|   27|\n",
      "|     16|   27|\n",
      "|     18|   27|\n",
      "|     22|   26|\n",
      "|     33|   26|\n",
      "|      6|   25|\n",
      "|     23|   25|\n",
      "|     31|   25|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fire_call_in_2018: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [CallType: string, AvailableDtTS: timestamp]\r\n",
       "fire_call_in_2018_2: org.apache.spark.sql.DataFrame = [CallType: string, AvailableDtTS: timestamp ... 1 more field]\r\n"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 7-b\n",
    "/*\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "//on selectionne d'abord les types d'appels d'incendie de l' anneé 2018\n",
    "val fire_call_in_2018=fireTSDF.select(\"CallType\",\"AvailableDtTS\").filter($\"CallType\"===\"Structure Fire\"||$\"CallType\"===\"Outside Fire\" \n",
    " and year(fireTSDF(\"AvailableDtTS\"))===2018)\n",
    "//on ajoute le colonne des semaines de l'annee 2018\n",
    "val fire_call_in_2018_2=fire_call_in_2018.withColumn(\"semaine\",weekofyear(fire_call_in_2018(\"AvailableDtTS\")))\n",
    "//enfin on compte le nombre d'appel pour chaque semaine en utiliant groupBy et on l'ordonne par ordre decroissant\n",
    "fire_call_in_2018_2.groupBy(\"semaine\").count().sort(desc(\"count\")).show()\n",
    "//le resulat montre que c'est la semaine 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "**Quels sont les quartiers de San Francisco qui ont connu le pire temps de réponse en 2018?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-------------------+---------------------+\n",
      "|         city|             Address|      AvailableDtTS|ResponseDelayedinMins|\n",
      "+-------------+--------------------+-------------------+---------------------+\n",
      "|San Francisco|600 Block of UNIO...|2018-03-18 09:15:56|            491.26666|\n",
      "|San Francisco|200 Block of MARK...|2018-01-21 04:51:33|            406.63333|\n",
      "|San Francisco|300 Block of EDDY ST|2018-03-23 02:57:27|            340.48334|\n",
      "|San Francisco|100 Block of CARL ST|2018-05-21 08:26:24|            175.86667|\n",
      "|San Francisco|200 Block of WILL...|2018-04-17 18:31:32|                155.8|\n",
      "|San Francisco|200 Block of THE ...|2018-06-08 15:10:52|            135.51666|\n",
      "|San Francisco|1900 Block of CAL...|2018-05-03 22:02:46|            129.01666|\n",
      "|San Francisco|1100 Block of 22N...|2018-03-05 09:58:11|                109.8|\n",
      "|San Francisco|1500 Block of 7TH...|2018-01-12 20:05:28|            106.13333|\n",
      "|San Francisco|500 Block of MINN...|2018-04-21 15:20:11|             94.71667|\n",
      "|San Francisco|2400 Block of KEI...|2018-04-27 13:48:55|            92.816666|\n",
      "|San Francisco|500 Block of MINN...|2018-04-21 15:16:59|            91.666664|\n",
      "|San Francisco|400 Block of 6TH AVE|2018-10-28 16:49:32|            90.433334|\n",
      "|San Francisco|500 Block of CART...|2018-08-09 21:17:48|             83.76667|\n",
      "|San Francisco| 200 Block of 6TH ST|2018-08-27 03:03:53|                 76.9|\n",
      "|San Francisco|1000 Block of POL...|2018-04-23 12:51:01|            76.566666|\n",
      "|San Francisco|4000 Block of 18T...|2018-06-08 13:32:42|             74.13333|\n",
      "|San Francisco|1200 Block of WEB...|2018-08-03 01:02:19|            67.916664|\n",
      "|San Francisco|1100 Block of POS...|2018-07-25 11:28:48|                67.45|\n",
      "|San Francisco| 200 Block of 8TH ST|2018-02-26 23:39:19|            64.683334|\n",
      "+-------------+--------------------+-------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Reponse 8\n",
    "/*\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "//On selectionne les quartier de sans francisco avec les temps de reponse en 2018 et on ordonne les temps de repone par ordre decroisssant \n",
    "fireTSDF.select(\"city\",\"Address\",\"AvailableDtTS\",\"ResponseDelayedinMins\")\n",
    ".filter(year(fireTSDF(\"AvailableDtTS\"))===2018).sort(desc(\"ResponseDelayedinMins\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "**Comment stocker les données du Dataframe sous format de fichiers Parquet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": " path file:/E:/MASTER IA/programmation_fontionelle/fire.parquet already exists.;\r",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: path file:/E:/MASTER IA/programmation_fontionelle/fire.parquet already exists.;\r",
      "  at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:121)\r",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\r",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\r",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\r",
      "  at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)\r",
      "  at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)\r",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)\r",
      "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)\r",
      "  at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:963)\r",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)\r",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)\r",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\r",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\r",
      "  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:963)\r",
      "  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:415)\r",
      "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:399)\r",
      "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:288)\r",
      "  at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:848)\r",
      "  ... 48 elided\r",
      ""
     ]
    }
   ],
   "source": [
    "//Reponse 9\n",
    "/*\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "fireTSDF.write.parquet(\"fire.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "**Comment relire les données stockée en format Parquet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": " Unable to infer schema for Parquet. It must be specified manually.;\r",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: Unable to infer schema for Parquet. It must be specified manually.;\r",
      "  at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$12(DataSource.scala:200)\r",
      "  at scala.Option.getOrElse(Option.scala:189)\r",
      "  at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:200)\r",
      "  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:408)\r",
      "  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)\r",
      "  at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)\r",
      "  at scala.Option.getOrElse(Option.scala:189)\r",
      "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)\r",
      "  at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:755)\r",
      "  at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:733)\r",
      "  ... 48 elided\r",
      ""
     ]
    }
   ],
   "source": [
    "//Reponse 10\n",
    "/*\n",
    "Ecrire ici votre code\n",
    "*/\n",
    "val fireparquetFileDF = spark.read.parquet(\"fire.parquet\")\n",
    "\n",
    "// Parquet files can also be used to create a temporary view and then used in SQL statements\n",
    "//parquetFileDF.createOrReplaceTempView(\"parquetFile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
